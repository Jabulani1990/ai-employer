import os
import time
from datetime import datetime, timedelta
from django.core.management.base import BaseCommand
from django.utils import timezone
from ai_workers.ai_property_manager.services.auto_property_listing.data_processing import DataProcessing
from ai_workers.ai_property_manager.tasks import process_csv_task
from ai_workers.models import BusinessAIWorker
from ai_workers.ai_property_manager.models import PropertyListing


class AutonomousDiscoveryEngine:
    """
    ðŸ¤– AUTONOMOUS PATTERN: Self-Discovery Engine
    
    This class transforms passive file watching into intelligent work discovery.
    Key autonomous concepts:
    1. Pattern Recognition - Learns business upload patterns
    2. Predictive Analytics - Anticipates when businesses need help
    3. Proactive Monitoring - Suggests optimizations without being asked
    4. Context Awareness - Remembers past performance to improve decisions
    """
    
    def __init__(self):
        self.learning_data = {}
        self.business_patterns = {}
        
    def analyze_business_patterns(self):
        """
        ðŸ§  LEARNING PATTERN: Analyze Historical Business Behavior
        
        Instead of just waiting for files, we analyze:
        - When do businesses typically upload?
        - How often do they upload?
        - What time patterns can we predict?
        """
        print("ðŸ” Analyzing business upload patterns...")
        
        # Get all active AI workers (businesses using property management)
        active_workers = BusinessAIWorker.objects.filter(
            status="active",
            ai_worker__name="AI Property Manager"
        )
        
        for worker in active_workers:
            business_id = worker.business.id
            
            # Analyze property upload patterns for this business
            recent_properties = PropertyListing.objects.filter(
                created_at__gte=timezone.now() - timedelta(days=30)
            ).order_by('-created_at')
            
            if recent_properties.exists():
                pattern = self._extract_upload_pattern(recent_properties)
                self.business_patterns[business_id] = pattern
                print(f"ðŸ“Š Business {worker.business.username}: {pattern['frequency']} uploads/week")
    
    def _extract_upload_pattern(self, properties):
        """
        ðŸŽ¯ PATTERN EXTRACTION: Learn from Historical Data
        
        This is core autonomous behavior - learning from the past to predict the future
        """
        if not properties:
            return {"frequency": 0, "best_times": [], "avg_batch_size": 0}
            
        # Calculate upload frequency
        first_upload = properties.last().created_at
        last_upload = properties.first().created_at
        days_span = (last_upload - first_upload).days or 1
        frequency = len(properties) / (days_span / 7)  # uploads per week
        
        # Find best upload times (hours of day)
        upload_hours = [prop.created_at.hour for prop in properties]
        best_times = list(set(upload_hours))  # Most common hours
        
        # Average batch size (how many properties per upload session)
        # Group by day and count
        daily_counts = {}
        for prop in properties:
            day_key = prop.created_at.date()
            daily_counts[day_key] = daily_counts.get(day_key, 0) + 1
        
        avg_batch_size = sum(daily_counts.values()) / len(daily_counts) if daily_counts else 0
        
        return {
            "frequency": round(frequency, 2),
            "best_times": best_times[:3],  # Top 3 most common hours
            "avg_batch_size": round(avg_batch_size, 1),
            "last_upload": last_upload,
            "total_properties": len(properties)
        }
    
    def predict_next_upload_window(self, business_id):
        """
        ðŸ”® PREDICTIVE INTELLIGENCE: When will they need us next?
        
        This is autonomous behavior - anticipating needs before they arise
        """
        if business_id not in self.business_patterns:
            return None
            
        pattern = self.business_patterns[business_id]
        if pattern["frequency"] == 0:
            return None
            
        # Calculate expected next upload time
        days_between_uploads = 7 / pattern["frequency"] if pattern["frequency"] > 0 else 7
        expected_next = pattern["last_upload"] + timedelta(days=days_between_uploads)
        
        # Check if we're in the predicted window (within 1 day)
        now = timezone.now()
        window_start = expected_next - timedelta(hours=12)
        window_end = expected_next + timedelta(hours=12)
        
        if window_start <= now <= window_end:
            return {
                "status": "predicted_upload_window",
                "confidence": min(pattern["frequency"] * 10, 90),  # Higher frequency = higher confidence
                "expected_time": expected_next,
                "suggested_actions": [
                    "Check for pending uploads",
                    "Prepare processing resources",
                    "Monitor upload folders closely"
                ]
            }
        
        return None
    
    def discover_optimization_opportunities(self):
        """
        ðŸ’¡ PROACTIVE INTELLIGENCE: Find ways to help businesses improve
        
        Instead of just processing what's given, suggest improvements
        """
        opportunities = []
        
        for business_id, pattern in self.business_patterns.items():
            # Find businesses that could optimize their workflow
            if pattern["frequency"] > 2:  # High frequency uploaders
                opportunities.append({
                    "business_id": business_id,
                    "type": "automation_opportunity",
                    "suggestion": "High upload frequency detected. Consider API integration for automated uploads.",
                    "potential_impact": "50% time savings on property uploads"
                })
            
            if pattern["avg_batch_size"] < 2:  # Small batch sizes
                opportunities.append({
                    "business_id": business_id,
                    "type": "efficiency_opportunity", 
                    "suggestion": "Small batch uploads detected. Consider batching properties for more efficient processing.",
                    "potential_impact": "30% faster processing times"
                })
        
        return opportunities
    
    def run_autonomous_discovery(self):
        """
        ðŸš€ MAIN AUTONOMOUS CYCLE: The heart of intelligent discovery
        
        This replaces passive waiting with active intelligence
        """
        print("ðŸ¤– Starting autonomous discovery cycle...")
        
        # Step 1: Learn from patterns
        self.analyze_business_patterns()
        
        # Step 2: Make predictions and take proactive actions
        for business_id in self.business_patterns.keys():
            prediction = self.predict_next_upload_window(business_id)
            if prediction:
                print(f"ðŸ”® Prediction for Business {business_id}: {prediction['status']}")
                print(f"   Confidence: {prediction['confidence']}%")
                print(f"   Suggested actions: {', '.join(prediction['suggested_actions'])}")
        
        # Step 3: Find optimization opportunities
        opportunities = self.discover_optimization_opportunities()
        for opp in opportunities:
            print(f"ðŸ’¡ Opportunity for Business {opp['business_id']}: {opp['suggestion']}")
        
        return {
            "patterns_analyzed": len(self.business_patterns),
            "predictions_made": sum(1 for bid in self.business_patterns.keys() 
                                  if self.predict_next_upload_window(bid)),
            "opportunities_found": len(opportunities)
        }


# class Command(BaseCommand):
#     help = "Watches for new CSV files in media/uploads and processes them"

#     def handle(self, *args, **kwargs):
#         watch_directory = "media/uploads"
#         processed_files = set()

#         self.stdout.write(self.style.SUCCESS("Starting file watcher..."))

#         while True:
#             files = set(os.listdir(watch_directory))
#             new_files = files - processed_files

#             for file in new_files:
#                 if file.endswith(".csv"):
#                     file_path = os.path.join(watch_directory, file)
#                     self.stdout.write(self.style.SUCCESS(f"Processing: {file_path}"))
#                     DataProcessing.process_data(file_path)

#             processed_files = files
#             time.sleep(5)  # Check every 5 seconds




class Command(BaseCommand):
    """
    ðŸ”„ TRANSFORMATION: From Reactive to Autonomous File Watcher
    
    OLD BEHAVIOR: Wait for files â†’ Process when found
    NEW BEHAVIOR: Intelligent discovery â†’ Predictive monitoring â†’ Proactive suggestions
    """
    help = "Autonomous AI Property Manager - Intelligent Discovery & Processing"
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.discovery_engine = AutonomousDiscoveryEngine()
        self.last_discovery_run = None
        self.discovery_interval = 300  # Run autonomous discovery every 5 minutes
        
    def add_arguments(self, parser):
        """Add command line options for autonomous behavior"""
        parser.add_argument(
            '--mode',
            choices=['reactive', 'autonomous', 'hybrid'],
            default='hybrid',
            help='Operating mode: reactive (old behavior), autonomous (new behavior), or hybrid (both)'
        )
        parser.add_argument(
            '--discovery-interval',
            type=int,
            default=300,
            help='Seconds between autonomous discovery runs (default: 300)'
        )

    def handle(self, *args, **options):
        """
        ðŸ§  AUTONOMOUS MAIN LOOP: Intelligent monitoring with multiple modes
        """
        mode = options['mode']
        self.discovery_interval = options['discovery_interval']
        
        watch_directory = "media/uploads"
        processed_files = set()
        
        self.stdout.write(
            self.style.SUCCESS(f"ðŸ¤– Starting Autonomous AI Property Manager in '{mode}' mode...")
        )
        
        if mode in ['autonomous', 'hybrid']:
            self.stdout.write(
                self.style.WARNING(f"ðŸ” Discovery engine will run every {self.discovery_interval} seconds")
            )
        
        while True:
            current_time = timezone.now()
            
            # ðŸ¤– AUTONOMOUS BEHAVIOR: Run discovery engine periodically
            if mode in ['autonomous', 'hybrid']:
                if (self.last_discovery_run is None or 
                    (current_time - self.last_discovery_run).seconds >= self.discovery_interval):
                    
                    self.stdout.write(self.style.HTTP_INFO("ðŸ” Running autonomous discovery..."))
                    discovery_results = self.discovery_engine.run_autonomous_discovery()
                    
                    self.stdout.write(
                        self.style.SUCCESS(
                            f"âœ… Discovery complete: {discovery_results['patterns_analyzed']} patterns analyzed, "
                            f"{discovery_results['predictions_made']} predictions made, "
                            f"{discovery_results['opportunities_found']} opportunities found"
                        )
                    )
                    self.last_discovery_run = current_time
            
            # ðŸ“ REACTIVE BEHAVIOR: Traditional file watching (enhanced)
            if mode in ['reactive', 'hybrid']:
                files = set(os.listdir(watch_directory)) if os.path.exists(watch_directory) else set()
                new_files = files - processed_files

                for file in new_files:
                    if file.endswith(".csv"):
                        file_path = os.path.join(watch_directory, file)
                        
                        # ðŸŽ¯ ENHANCED PROCESSING: Add context from discovery engine
                        business_context = self._get_business_context_for_file(file_path)
                        
                        self.stdout.write(
                            self.style.SUCCESS(f"ðŸ“„ Processing: {file_path}")
                        )
                        
                        if business_context:
                            self.stdout.write(
                                self.style.HTTP_INFO(f"ðŸ§  Context: {business_context}")
                            )

                        # Send task to Celery with enhanced context
                        process_csv_task.delay(file_path)

                processed_files = files
            
            # Sleep with intelligent interval adjustment
            sleep_time = 5 if mode == 'reactive' else max(5, self.discovery_interval // 60)
            time.sleep(sleep_time)
    
    def _get_business_context_for_file(self, file_path):
        """
        ðŸ§  CONTEXTUAL INTELLIGENCE: Provide business context for file processing
        
        This is autonomous behavior - using learned patterns to enhance processing
        """
        try:
            # Try to identify which business this file belongs to
            # In a real system, you might parse filename patterns or folder structure
            filename = os.path.basename(file_path)
            
            # For now, provide general context based on discovery patterns
            total_patterns = len(self.discovery_engine.business_patterns)
            if total_patterns > 0:
                return f"Processing with context from {total_patterns} business patterns learned"
            
            return "First-time processing - will learn patterns for future optimization"
            
        except Exception as e:
            return f"Context analysis failed: {str(e)}"
